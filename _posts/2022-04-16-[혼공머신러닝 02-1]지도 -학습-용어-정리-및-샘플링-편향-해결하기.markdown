---
layout: post
title:  "[혼공머신러닝 02-1]지도 학습 용어 정리 및 샘플링 편향 해결하기"
author: 김예나
date:   2022-04-16 21:55:00 +0900
categories: [study]
tags: [machine learning]
math: true
mermaid: true
---
  

## 1\. 지도 학습 용어 정리


지도 학습 : 훈련하기 위한 데이터와 정답이 필요한 학습
입력 : 지도 학습에서 훈련을 위해 필요한 데이터
타깃 : 지도 학습에서 훈련을 위해 필요한 데이터의 정답
훈련 데이터 : 입력 + 타깃
특성 : 입력으로 사용된 데이터의 열(길이, 무게 등)
테스트 세트 : 평가에 사용하는 데이터
훈련 세트 : 훈련에 사용되는 데이터


## 2\. 샘플링 편향


지난 장에서 공부했던 도미와 빙어 데이터 분류 모델 평가에는 한 가지 문제가 있었습니다. 훈련에 사용한 데이터를 그대로 평가에 사용했기 때문에, 정답을 전부 알려준 뒤 답을 맞춰 보라는 식의 문제가 되었던 것입니다. 그래서 이번 장에서는 슬라이싱을 이용해 데이터를 테스트 세트와 훈련 세트로 분류합니다.


```python
fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 
                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 
                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]
fish_data = [[l, w] for l, w in zip(fish_length, fish_weight)]
fish_target = [1]*35 + [0]*14
# 0 ~ 34번 원소를 훈련 세트로
train_input = fish_data[:35]
train_target = fish_target[:35]

# 35 ~ 48번 원소를 테스트 세트로
test_input = fish_data[35:]
test_target = fish_target[35:]
```


그런데 여기서 다시 한 번 문제가 발생하게 됩니다.


```python
from sklearn.neighbors import KNeighborsClassifier

kn = KNeighborsClassifier()
kn.fit(train_input, train_target)
kn.score(test_input, test_target)
```


이와 같이 테스트를 해보았더니, 결과가 0, 즉 0%의 정확도가 나왔다는 것입니다. 이런 일이 발생한 이유는 35번째까지의 데이터는 도미, 그 이후의 데이터는 빙어로 구성되어 있는데 훈련은 도미로만 하고, 테스트는 빙어로만 했으니 어떤 테이터를 집어넣더라도 모델은 도미로 판단하기 때문에 이런 극단적인 정확도가 나온 것입니다.

이를 해결하기 위한 방법으로 이 책에서는 numpy의 shuffle 명령어와 배열 인덱싱을 제시합니다. 해결 방법의 순서는 다음과 같습니다.


### (1) 파이썬 리스트를 넘파이 배열로 변환


```python
import numpy as np
# 파이썬 리스트를 넘파이 배열로 변환
input_arr = np.array(fish_data)
target_arr = np.array(fish_target)
```


### (2) index 배열을 생성하고 무작위로 섞음


```python
np.random.seed(42) # 무작위 결과를 실행 시마다 동일하게 만들 수 있도록 하는 역할
index = np.arange(49) # 0 ~ 48까지 1씩 증가하는 배열 생성
np.random.shuffle(index) # 배열을 무작위로 섞음
```


### (3) 배열 인덱싱을 이용해 훈련 세트와 테스트 세트를 섞음


```python
# 배열 인덱싱을 이용해 훈련 세트를 섞음
train_input = input_arr[index[:35]]
train_target = target_arr[index[:35]]
# 배열 인덱싱을 이용해 테스트 세트를 섞음
test_input = input_arr[index[35:]]
test_target = target_arr[index[35:]]
```


이와 같은 방법으로 모델을 훈련시켰을 때 우리는 더 높은 정확도의 결과를 얻을 수 있게 됩니다.


```python
kn.fit(train_input, train_target) # 훈련
kn.score(test_input, test_target) # 평가
```

이 경우의 결과는 1.0으로, 모든 테스트 세트의 타겟값을 맞춰 100%의 정확도를 보여주었습니다.


공부한 내용의 전체 코드는 github에 작성해 두었습니다.
<https://github.com/ynkim0/study/blob/main/2-1.ipynb>