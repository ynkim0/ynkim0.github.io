---
layout: post
title:  "[혼공머신러닝 01-3]k-최근접 이웃 알고리즘"
author: 김예나
date:   2022-04-16 21:10:00 +0900
categories: [study]
tags: [machine learning]
math: true
mermaid: true
---
  

포스팅에 앞서, 앞으로 혼공머신러닝에 관한 포스팅은 혼자 공부하는 머신러닝+딥러닝의 책 내용을 공부하며 정리한 것이라는 점을 밝힙니다.
혼공머신러닝 : <https://books.google.co.kr/books?id=9Q0REAAAQBAJ&printsec=frontcover&dq=%ED%98%BC%EA%B3%B5%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D&hl=ko&sa=X&ved=2ahUKEwirhffTyZj3AhWEMd4KHfqVDy4Q6AF6BAgFEAI#v=onepage&q=%ED%98%BC%EA%B3%B5%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D&f=false>


이 책에서는 도미와 빙어를 구분하는 예제로 k-최근접 이웃 알고리즘을 소개하였습니다. 다음은 x축을 생선의 길이, y축을 생선의 무게로 정하였을 때 도미와 방어의 데이터를 산점도로 나타낸 것입니다.

![image](https://user-images.githubusercontent.com/80688900/163674760-09701046-adba-4fd0-8df3-39bbe34b3759.png)

k-최근접 이웃 알고리즘을 이용하면 정체를 모르는 어떤 생선의 길이와 무게를 알고 있을 때 그것이 도미인지 방어인지 예측해볼 수 있습니다.

이 알고리즘은 ‘거리’를 기반으로 합니다. 이 때 거리란, 수학에서 평면 위의 두 점 사이의 거리입니다. 어떤 데이터를 이 알고리즘으로 훈련한 모델에 넣을 경우, 가장 이웃한 n개의 점을 찾아서 그것들이 도미(1)인지 방어(0)인지를 확인합니다.

직접 코드로 확인해봅시다.


## 1\. 데이터 준비하기


### (1) 도미와 빙어의 길이와 무게 리스트 준비


```python
bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0] # 도미의 길이
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0] # 도미의 무게
smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0] # 빙어의 길이
smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] # 빙어의 무게
```

### (2) 리스트 합치기


```python
# length와 weight의 35번째까지의 데이터는 도미, 그 이후의 데이터는 빙어
length = bream_length+smelt_length
weight = bream_weight+smelt_weight
```


### (3) 모델에 넣을 수 있는 형태의 2차원 리스트 만들기


```python
fish_data = [[l, w] for l, w in zip(length, weight)] # 모델에 넣을 수 있는 형태로 만들기, zip 함수는 각 리스트에서 원소를 한 개씩 순서대로 추출
```

행에는 각 샘플 별 특성이, 열에는 특성 별 샘플이 나열되어 있는 형태로 만듭니다.


### (4) 타겟 리스트 만들기


```python
fish_target = [1]*35 + [0]*14 # 1:도미, 0:빙어
```


## 2\. 모델 훈련시키고 결과 얻기


### (1) 모델 준비


```python
from sklearn.neighbors import KNeighborsClassifier # K-최근접이웃 분류 모델
kn = KNeighborsClassifier() # 객체 생성
```


### (2) 훈련


```python
kn.fit(fish_data, fish_target)# 훈련하기
```


### (3) 평가


```python
kn.score(fish_data, fish_target) # 모델의 정확도 분석(데이터를 모두 맞추었으면 1, 맞추지 못했으면 0)
```


### (4) 예측


```python
kn.predict([[30, 600]]) # 학습된 모델로 해당 데이터가 어디에 속할지 예측
```


책에는 나오지 않았지만, 전체(49개) 데이터를 모두 참조하도록 하였을 때 어떤 데이터를 넣더라도 35(전체 데이터 중 도미 데이터의 수)/49(전체 데이터의 수)의 결과를 얻었던 것으로 미루어 볼 때 아마 이 알고리즘은 n개 중 도미의 수 * 1 + n개 중 방어의 수 * 0 / n을 계산하여 출력할 것입니다. 복잡한 계산식은 아니기 때문에 데이터의 수가 많지 않다면 손으로도 거리를 계산하고, 근접한 이웃을 구해 결과를 내는 작업을 해볼 수 있을 것 같습니다.


공부한 내용의 전체 코드는 github에 작성해 두었습니다.
<https://github.com/ynkim0/study/blob/main/1-3.ipynb>